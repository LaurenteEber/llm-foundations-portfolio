# Roadmap (6 terms) – overview

## Purpose

This roadmap is designed to:

1) Ensure I enter the Master's in AI with strong prerequisites and practical fluency, and  
2) Provide public evidence (projects + reports) that I can succeed academically despite a non-CS undergraduate background.

The roadmap runs three parallel tracks:

- Track 1: Models and LLMs  
- Track 2: Mathematics and statistics  
- Track 3: Engineering and MLOps for AI/LLMs

The detailed audited route documents are stored under `docs/roadmaps/`.

## Foundation add-ons (pre-term)

These two modules address the most common readiness gaps for non-CS backgrounds:

- **CS fundamentals:** data structures, algorithms and complexity  
  Deliverable repo: `cs-fundamentals-for-ai`

- **Reinforcement learning + planning foundations:** bandits + MDPs + Q-learning  
  Deliverable repo: `rl-and-planning-foundations`

## Term-by-term plan

### Term 1 – practical ML foundations and basic calculus

- Track 1: classical supervised ML end-to-end.
- Track 2: operational calculus + start linear algebra.
- Track 3: engineering fundamentals (repo structure, tests, Git).

Deliverable project: `ml-classic-portfolio`.

### Term 2 – neural networks and software architecture for ML

- Track 1: deep learning basics (training stability, regularisation).
- Track 2: linear algebra for representations and analysis (PCA).
- Track 3: clean architecture for ML systems (modules, configs, tests).

Deliverable project: `dl-systems-basics`.

### Term 3 – modern NLP, probability and text data pipelines

- Track 1: NLP foundations (n-grams, embeddings, neural NLP pre-transformer).
- Track 2: probability for language modelling.
- Track 3: data engineering for text corpora + tokenisation.

Deliverable project: `text-corpus-and-tokenizer`.

### Term 4 – transformers, optimisation and GPU computing

- Track 1: transformer architecture + small language model training.
- Track 2: optimisation for neural networks (gradient methods, stability).
- Track 3: GPU compute + profiling + (intro) distributed training.

Deliverable project: `mini-transformer-lab`.

### Term 5 – practical LLMs, evaluation and MLOps

- Track 1: fine-tuning / PEFT for open-source LLMs; evaluation design.
- Track 2: statistical inference + information theory (cross-entropy, KL, perplexity).
- Track 3: experiment tracking, versioning, CI checks; reproducible evaluation suites.

Deliverable project: `llm-experiments-lab`.

### Term 6 – alignment, RAG systems and LLMOps in production

- Track 1: alignment at a high level + RAG and tool-using systems.
- Track 2: high-dimensional probability and generalisation (conceptual, applied).
- Track 3: LLMOps, serving, observability and safety controls.

Deliverable project: `llm-rag-assistant`.

## References (audited documents)

- Track 1 route: `docs/roadmaps/route_1_models_llms.md`
- Track 2 route: `docs/roadmaps/route_2_math_stats.md`
- Track 3 route: `docs/roadmaps/route_3_engineering_mlops.md`
- Integrated roadmap (projects): `docs/roadmaps/integrated_roadmap.md`
