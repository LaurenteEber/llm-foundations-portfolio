# Background for MS in AI (draft)

## Summary

I am an Economics graduate with professional experience in strategic planning, monitoring and evaluation in the public sector (Peru).
I am preparing to pursue a Master's in Artificial Intelligence at UT Austin, with the goal of building strong technical foundations
and the ability to contribute to applied research and engineering of modern AI systems, including (but not limited to) LLM-based systems.

This document provides a concise narrative that can be adapted into a Statement of Purpose (SOP).

## Academic and professional background

- Degree: Economics (undergraduate).
- Professional domain: public sector strategic planning, performance monitoring and evaluation.
- Current role: Monitoring and evaluation specialist at CEPLAN (Centro Nacional de Planeamiento Estratégico).
- Typical work: designing indicators, evaluating strategic plans, synthesising evidence for decision-making.

## Why AI (and why now)

My interest in AI is driven by two complementary motivations:

1) **Methodological depth:** modern ML and deep learning provide powerful tools for prediction, representation learning and decision support.  
2) **System-level impact:** LLM-based systems and retrieval-augmented generation can improve access to knowledge and support analysis workflows,
   including policy analysis and complex planning contexts.

## Preparation plan (evidence-based)

To ensure I enter the program ready for graduate-level AI coursework, I structured a self-directed curriculum with three tracks:

- Track 1: Models and LLMs (ML → DL → NLP → transformers → practical LLMs)  
- Track 2: Mathematics and statistics (calculus, linear algebra, probability, inference, optimisation, information theory)  
- Track 3: Engineering and MLOps (software engineering, data engineering, GPU training, tracking, LLMOps, serving and observability)

Deliverables are implemented as public projects with technical reports and reproducible code.
See `PROJECTS.md` and `docs/Mapping_to_MS_prerequisites.md`.

## Responsible AI

Across projects, I include an explicit “Responsible AI” section covering:
- limitations and failure modes,
- fairness and bias considerations (when applicable),
- safety risks (prompt injection, hallucinations),
- mitigation strategies and monitoring.

## Contact

- Name: [Your full name]
- Email: [your.email@example.com]
- GitHub: https://github.com/[your-username]
